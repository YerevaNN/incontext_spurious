_target_: src.models.InContextLearner

network:
  _target_: transformers.GPTJModel
  config:
    _target_: transformers.GPTJConfig
    n_positions: 512
    n_embd: 768
    n_layer: 6
    n_head: 8
    n_inner: 3072  # Adjusted as per convention: 4 * n_embd
    resid_pdrop: 0.0
    embd_pdrop: 0.0
    attn_pdrop: 0.0
    use_cache: False
loss_fn:
  _target_: src.utils.custom_loss_functions.ContextBNEWithLogits
  keep_n: 101
with_spurious_token: ${datamodule.include_spurious}
val_sets: [inner, outer, inner_outer]